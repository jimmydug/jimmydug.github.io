<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="线性分类器（来自python机器学习及实践） &amp;emsp;&amp;emsp;线性分类器，是一种假设特征feature与分类结果target/label存在线性关系的模型，通过累加计算每个维度的特征与各自权重的乘积来帮助进行类别决策。">
<meta property="og:type" content="article">
<meta property="og:title" content="线性分类器">
<meta property="og:url" content="http://yoursite.com/2017/08/24/线性分类器/index.html">
<meta property="og:site_name" content="jimmydug's blog">
<meta property="og:description" content="线性分类器（来自python机器学习及实践） &amp;emsp;&amp;emsp;线性分类器，是一种假设特征feature与分类结果target/label存在线性关系的模型，通过累加计算每个维度的特征与各自权重的乘积来帮助进行类别决策。">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=\Large f(w,x,b)=w^Tx %2b b">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=\Large g(z)=\frac{1}{1 %2b e^{-z}}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=\Large h_{w, b}(x)=\frac{1}{1 %2b e^{-(w^Tx %2b b)}}">
<meta property="og:updated_time" content="2017-09-10T11:28:58.913Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="线性分类器">
<meta name="twitter:description" content="线性分类器（来自python机器学习及实践） &amp;emsp;&amp;emsp;线性分类器，是一种假设特征feature与分类结果target/label存在线性关系的模型，通过累加计算每个维度的特征与各自权重的乘积来帮助进行类别决策。">
<meta name="twitter:image" content="http://chart.googleapis.com/chart?cht=tx&chl=\Large f(w,x,b)=w^Tx %2b b">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":true},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/08/24/线性分类器/"/>





  <title> 线性分类器 | jimmydug's blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">jimmydug's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Love Life&Coding</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/24/线性分类器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jimmydug">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jimmydug's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                线性分类器
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-24T16:48:26+08:00">
                2017-08-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="线性分类器（来自python机器学习及实践）"><a href="#线性分类器（来自python机器学习及实践）" class="headerlink" title="线性分类器（来自python机器学习及实践）"></a>线性分类器（来自python机器学习及实践）</h2><p> &emsp;&emsp;线性分类器，是一种假设特征feature与分类结果target/label存在线性关系的模型，通过累加计算每个维度的特征与各自权重的乘积来帮助进行类别决策。<br><a id="more"></a><br>&emsp;&emsp;假设定义x = (x1,x2,x3,…,xn)为n维特征<strong>列</strong>向量，同时n维<strong>列</strong>向量w = (w1,w2,w3,…,wn)为对应的<strong>权重</strong>，或者叫做系数coefficient，同时为了避免其过坐标原点这种硬性假设，增加截距(intercept)b。于是这种线性关系可表示为:<img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large f(w,x,b)=w^Tx %2b b" style="border:none;"><br>&emsp;&emsp;对于处理二分类问题，我们希望f取值于(0, 1),一般以0.5为阈值，因此可以用Logistic函数(也叫Sigmoid函数)将f映射到(0, 1),函数式为：<img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large g(z)=\frac{1}{1 %2b e^{-z}}" style="border:none;"><br>&emsp;&emsp;如果将z替换为f，则得到经典的<strong>Logistic回归模型</strong>(虽然叫回归，但是的确是用来处理分类问题)：<br><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large h_{w, b}(x)=\frac{1}{1 %2b e^{-(w^Tx %2b b)}}" style="border:none;"><br>&emsp;&emsp;Logistic回归模型处理二分类任务的主要原理：将测试数据集上的特征向量乘以最优化方法得来的回归系数，再将乘积结果求和输入到sigmoid函数中即可，结果大于0.5则预测类别标签为1，否则为0。其中最优化方法有许多，这里使用的是随机梯度上升。<br>&emsp;&emsp;其中w，b即为我们要在训练数据集中学习到的参数，<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data" target="_blank" rel="external">获取数据点击这里</a>,总体数据(包含train和test)维度为(699, 11),1列为数据id，1列为数据的label/target(2或4)，9列为医学特征(已经量化为1-10)，数据中有16个缺失值，已经用？标出。<br>下面将使用<strong>Logistic回归</strong>和<strong>随机梯度下降</strong>(Stochastic Gradient Descend)俩种线性分类模型来进行<strong>良/恶性乳腺肿瘤预测</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div></pre></td><td class="code"><pre><div class="line">import pandas as pd   <span class="comment">#pandas用于对数据处理和分析</span></div><div class="line">import numpy as np    <span class="comment">#numpy提供向量，矩阵运算功能</span></div><div class="line"><span class="comment"># 创建特征列表，No.1为每行数据id，No.2-10为9个feature，No.11为label </span></div><div class="line">column_names = [<span class="string">'Sample code number'</span>, <span class="string">'Clump Thickness'</span>, <span class="string">'Uniformity od Cell Size'</span>, <span class="string">'Uniformity of Cell Shape'</span>, <span class="string">'Marginal Adhesion'</span>, <span class="string">'Single Epithelial Cell Size'</span>, <span class="string">'Bare Nuclei'</span>, <span class="string">'Bland Chromatin'</span>, <span class="string">'Normal Nucleoli'</span>, <span class="string">'Mitoses'</span>, <span class="string">'Class'</span>]</div><div class="line"><span class="comment"># 使用pandas.read_csv函数从网页读取数据</span></div><div class="line">data = pd.read_csv(<span class="string">'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'</span>, names = column_names)</div><div class="line"><span class="comment"># 将标准缺失值np.nan替换缺失值？</span></div><div class="line">data = data.replace(to_replace=<span class="string">'?'</span>, value = np.nan)</div><div class="line"><span class="comment"># 丢弃带有缺失值的数据（只要有一个维度缺失）</span></div><div class="line">data = data.dropna(how=<span class="string">'any'</span>)</div><div class="line"><span class="comment">#16个数据样本有缺失值，去除后数据样本总数由699变为683</span></div><div class="line">&lt;&lt;&lt;data.shape</div><div class="line">	(683, 11)</div><div class="line"><span class="comment"># sklearn.cross_validation中的train_test_split模块用于分割数据</span></div><div class="line">from sklearn.cross_validation import train_test_split</div><div class="line"><span class="comment"># 随机采样75%数据样本作训练集，25%作测试集</span></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(data[column_names[1:10]], data[column_names[10]], test_size=0.25, random_state=33)</div><div class="line"><span class="comment"># 训练样本的数量和类别分布</span></div><div class="line">&lt;&lt;&lt;y_train.value_counts()</div><div class="line">	2    344</div><div class="line">	4    168</div><div class="line">	Name: Class, dtype: int64</div><div class="line"><span class="comment"># 测试样本的数量和类别分布</span></div><div class="line">&lt;&lt;&lt;y_test.value_counts()</div><div class="line">	2    100</div><div class="line">	4     71</div><div class="line">	Name: Class, dtype: int64</div><div class="line"><span class="comment"># 导入预处理中的StandardScaler模块来标准化数据</span></div><div class="line">from sklearn.preprocessing import StandardScaler</div><div class="line"><span class="comment"># 导入线性模型中的逻辑斯蒂回归模型和随机梯度下降模型</span></div><div class="line">from sklearn.linear_model import LogisticRegression</div><div class="line">from sklearn.linear_model import SGDClassifier</div><div class="line"><span class="comment"># 标准化数据，保证每个维度的特征数据方差为1，均值为0，使得预测结果不会被某些维度过大的特征值而主导</span></div><div class="line">ss = StandardScaler()</div><div class="line"><span class="comment"># 前者合并fit和transform两个方法，根据X_train设置标准化缩放比例并标准化,后者用之前设置的比例标准化X_test</span></div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.transform(X_test)</div><div class="line"><span class="comment"># 初始化俩种模型</span></div><div class="line">lr = LogisticRegression()</div><div class="line">sgdc = SGDClassifier()</div><div class="line"><span class="comment"># fit函数来训练模型参数</span></div><div class="line">lr.fit(X_train, y_train)</div><div class="line"><span class="comment"># 训练显示 </span></div><div class="line">&lt;&lt;&lt;LogisticRegression(C=1.0, class_weight=None, 	dual=False, fit_intercept=True,</div><div class="line">      	intercept_scaling=1, max_iter=100, multi_class=<span class="string">'ovr'</span>, n_jobs=1,</div><div class="line">      	penalty=<span class="string">'l2'</span>, random_state=None, solver=<span class="string">'liblinear'</span>, tol=0.0001,</div><div class="line">      	verbose=0, warm_start=False)</div><div class="line"><span class="comment"># 训练好的模型lr对测试集X_test预测，结果为lr_y_predict</span></div><div class="line">lr_y_predict = lr.predict(X_test)</div><div class="line"><span class="comment"># 同样随机梯度下降模型训练</span></div><div class="line">sgdc.fit(X_train, y_train)</div><div class="line"><span class="comment"># 训练显示 </span></div><div class="line">&lt;&lt;&lt;SGDClassifier(alpha=0.0001, average=False, 	class_weight=None, epsilon=0.1,</div><div class="line">   		eta0=0.0, fit_intercept=True, l1_ratio=0.15,</div><div class="line">   		learning_rate=<span class="string">'optimal'</span>, loss=<span class="string">'hinge'</span>, n_iter=5, n_jobs=1,</div><div class="line">   		penalty=<span class="string">'l2'</span>, power_t=0.5, random_state=None, shuffle=True,</div><div class="line">   		verbose=0, warm_start=False)</div><div class="line"><span class="comment"># 训练好的模型对X_test预测，结果为sgdc_y_predict</span></div><div class="line">sgdc_y_predict = sgdc.predict(X_test)</div><div class="line"><span class="comment"># 导入classification_report模块对分类器性能进行评价</span></div><div class="line">from sklearn.metrics import classification_report</div><div class="line"><span class="comment"># 使用逻辑斯蒂回归模型自带的评分函数score获得在测试集上的准确性accuracy结果</span></div><div class="line"><span class="built_in">print</span>(<span class="string">'accuracy of lr classifier:'</span>, lr.score(X_test, y_test))</div><div class="line">&lt;&lt;&lt;accuracy of lr classifier: 0.988304093567</div><div class="line"><span class="comment"># 获得其他三个指标精确率precision，召回率recall，F1指数f1measure的结果</span></div><div class="line"><span class="built_in">print</span>(classification_report(y_test, lr_y_predict, target_names=[<span class="string">'Benign'</span>, <span class="string">'Malignant'</span>]))</div><div class="line">         precision    recall  f1-score   support</div><div class="line"> Benign       0.99      0.99      0.99       100</div><div class="line">Malignant       0.99      0.99      0.99        71</div><div class="line"></div><div class="line">avg / total       0.99      0.99      0.99       171</div><div class="line"><span class="comment"># 随机梯度模型同上</span></div><div class="line"><span class="built_in">print</span>(<span class="string">'Accuarcy of SGD Classifier:'</span>, sgdc.score(X_test, y_test))</div><div class="line">&lt;&lt;&lt;Accuarcy of SGD Classifier: 0.982456140351</div><div class="line"><span class="built_in">print</span>(classification_report(y_test, sgdc_y_predict, target_names=[<span class="string">'Benign'</span>, <span class="string">'Malignant'</span>]))</div><div class="line">         precision    recall  f1-score   support</div><div class="line"> Benign       1.00      0.97      0.98       100</div><div class="line"> Malignant       0.96      1.00      0.98        71</div><div class="line"></div><div class="line">avg / total       0.98      0.98      0.98       171</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;线性分类模型受限于数据特征与分类目标之间存在<strong>线性假设</strong>，这里使用的俩种模型为LogisticRegression与SGDClassifier，前者对参数的计算采用精确解析的方式，计算时间长但模型性能略高，后者用随机梯度下降算法估计模型参数，计算时间短但性能没有前者高。（虽然名为Regression但是处理的是分类问题）</p>
<h2 id="梯度上升-来自机器学习实战第5章"><a href="#梯度上升-来自机器学习实战第5章" class="headerlink" title="梯度上升(来自机器学习实战第5章)"></a>梯度上升(来自机器学习实战第5章)</h2><p>&emsp;&emsp;梯度上升法的思想是：要想找到某函数的最大值，最好的办法是沿着该函数的梯度方向去找，每次沿梯度方向移动一小步(alpha)，每次移动后都会重新计算梯度方向，每次迭代时都会使用所有数据计算梯度方向。<br>示例使用了Logistic回归模型，回归系数最优化算法为随机梯度上升法。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">import numpy as np</div><div class="line"><span class="comment">#三列参数为w0,w1,w2, w0即为截距b，x0恒为1</span></div><div class="line">import matplotlib.pyplot as plt</div><div class="line">dataMat = np.zeros((100, 3))</div><div class="line">labelMat = np.zeros((100, 1))</div><div class="line">i = 0</div><div class="line">with open(<span class="string">'testSet.txt'</span>, <span class="string">'r'</span>) as f:</div><div class="line">	<span class="keyword">for</span> each_line <span class="keyword">in</span> f.readlines():</div><div class="line">    	<span class="comment">#去俩端空格，返回一个list，split()默认按空格分</span></div><div class="line">    	lineArr = each_line.strip().split()</div><div class="line">    	<span class="comment">#添加x0,且恒为1，则w0x0恒定</span></div><div class="line">    	dataMat[i] = [1.0, <span class="built_in">float</span>(lineArr[0]), <span class="built_in">float</span>(lineArr[1])]</div><div class="line">    	labelMat[i] = int(lineArr[2])</div><div class="line">    	i+=1</div><div class="line"><span class="comment"># 接受参数类型和返回一致</span></div><div class="line">def sigmoid(<span class="keyword">in</span>X):</div><div class="line">	<span class="built_in">return</span> 1.0/(1+np.exp(-inX))</div><div class="line"><span class="comment">#每次梯度上升移动的步长和迭代次数</span></div><div class="line">alpha = 0.001</div><div class="line">maxCycles = 500</div><div class="line"><span class="comment">#权重初始参数值为1</span></div><div class="line">weights = np.ones((3,1))</div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</div><div class="line">	<span class="comment">#(100,3)*(3,1),矩阵乘法为np.dot(),对应元素相乘为*</span></div><div class="line">	h = sigmoid(np.dot(dataMat, weights))</div><div class="line">	<span class="comment">#(100,1)    </span></div><div class="line">	error = (labelMat - h)            </div><div class="line">	<span class="comment">#转置,和.T相同 (3, 100)*(100, 1)</span></div><div class="line">	weights = weights + alpha * np.dot(dataMat.transpose(), error)</div><div class="line"><span class="comment">#.shape和np.shape(Mat)等价</span></div><div class="line">n = np.shape(dataMat)[0] <span class="comment">#100</span></div><div class="line">x1 = []</div><div class="line">x2 = []</div><div class="line">y1 = []</div><div class="line">y2 = []</div><div class="line"><span class="comment"># 遍历每个数据</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">	<span class="keyword">if</span> int(labelMat[i])== 1:</div><div class="line">     <span class="comment"># [i,1]和[i][1]等价，不同类型数据分开</span></div><div class="line">    	x1.append(dataMat[i][1]), y1.append(dataMat[i][2])</div><div class="line">	<span class="keyword">else</span>:</div><div class="line">    	x2.append(dataMat[i][1]), y2.append(dataMat[i][2])</div><div class="line">fig = plt.figure()</div><div class="line">ax = fig.add_subplot(1,1,1)</div><div class="line"><span class="comment"># 画数据散点图</span></div><div class="line">ax.scatter(x1, y1, s=30, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>)</div><div class="line">ax.scatter(x2, y2, s=30, c=<span class="string">'green'</span>)</div><div class="line"><span class="comment"># 作学习到的分隔线</span></div><div class="line">x = np.arange(-3.0, 3.0, 0.1)</div><div class="line">y = (-weights[0][0]-weights[1][0]*x)/weights[2][0]</div><div class="line">ax.plot(x, y)</div><div class="line">plt.xlabel(<span class="string">'X1'</span>); plt.ylabel(<span class="string">'X2'</span>);</div><div class="line">plt.show()</div></pre></td></tr></table></figure></p>
<h2 id="随机梯度上升-SGA"><a href="#随机梯度上升-SGA" class="headerlink" title="随机梯度上升(SGA)"></a>随机梯度上升(SGA)</h2><p>&emsp;&emsp;梯度上升法每次更新回归系数时都要遍历整个数据集(进行了矩阵乘法)，随机梯度的思想是一次仅用一个数据来更新回归系数，属于<strong>增量式更新</strong>，也是一种<strong>在线学习算法</strong>。<br>这是我自己改进的代码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">weights = np.ones((3,1))</div><div class="line">m,n = np.shape(dataMat)</div><div class="line"><span class="comment"># 迭代次数</span></div><div class="line">numIter=150</div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</div><div class="line"><span class="comment"># 不断删减的数据索引，每次迭代用过的数据不再用</span></div><div class="line">	dataIndex = list(range(m))</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">    	<span class="comment"># alpha不断减小，但不为0</span></div><div class="line">    	alpha = 4/(1.0+j+i)+0.0001 </div><div class="line">    	<span class="comment"># 随机抽取每次计算梯度的幸运样本</span></div><div class="line">    	randIndex = int(np.random.uniform(0,len(dataIndex)))<span class="comment">#go to 0 because of the constant</span></div><div class="line">		<span class="comment"># h是一维数组(1, 1) (1,3)*(3,1)</span></div><div class="line">    	h = sigmoid(np.dot(dataMat[randIndex], weights))</div><div class="line">    	<span class="comment"># error也是一个数值</span></div><div class="line">    	error = labelMat[randIndex][0] - h[0]</div><div class="line">    	<span class="comment"># weights(3,1), error(1,1) dataMat[randIndex]为(1, 3).T</span></div><div class="line">   		weights = weights + alpha * error * dataMat[randIndex].transpose()</div><div class="line">    	<span class="comment"># 每次迭代中相同数据仅出现一次</span></div><div class="line">    	del(dataIndex[randIndex])</div></pre></td></tr></table></figure></p>
<p>这是书上的代码，改变了weights的维度。不知道为什么我写的和书上的最后的分隔线不一样，我写的有错误，但是我找不到，呜呜呜呜呜<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">m,n = np.shape(dataMat)</div><div class="line"><span class="comment">#这里是(1, n)</span></div><div class="line">weights = np.ones(n)</div><div class="line"><span class="comment">#迭代次数   </span></div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(150):</div><div class="line">dataIndex = list(range(m))</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">	alpha = 4/(1.0+j+i)+0.0001    </div><div class="line">	randIndex = int(np.random.uniform(0,len(dataIndex)))</div><div class="line"> 	<span class="comment">#这里用*是对应乘，没毛病</span></div><div class="line">	h = sigmoid(np.sum(dataMat[randIndex]*weights))</div><div class="line">	<span class="comment"># h,error都是数值</span></div><div class="line">	    error = labelMat[randIndex] - h</div><div class="line">    weights = weights + alpha * error * dataMat[randIndex]</div><div class="line">    del(dataIndex[randIndex])</div></pre></td></tr></table></figure></p>
<p>随机梯度算法相比来说一是alpha每次迭代过程中都会调整，二是每次更新回归系数的时候样本是随机选取的，所以系数值不会出现周期变化。</p>
<h2 id="用Logistic回归进行二分类预测（分类任务）"><a href="#用Logistic回归进行二分类预测（分类任务）" class="headerlink" title="用Logistic回归进行二分类预测（分类任务）"></a>用Logistic回归进行二分类预测（分类任务）</h2><p>&emsp;&emsp;Logistic回归模型处理二分类任务的主要原理：将测试数据集上的特征向量乘以最优化方法得来的回归系数，再将乘积结果求和输入到sigmoid函数中即可，结果大于0.5则预测类别标签为1，否则为0。其中最优化方法有许多，这里使用的是随机梯度上升。<br>数据集中有部分特征值缺失，对于缺失值作如下处理：</p>
<p>1.对训练集中特征缺失情况下用0代替，由回归系数公式：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">h = sigmoid(np.sum(dataMat[randIndex]*weights))</div><div class="line">error = labelMat[randIndex] - h</div><div class="line">weights = weights + alpha * error * dataMat[randIndex]</div><div class="line">当dataMat某特征值为0时，那么该特征的系数将不做更新，同时因为sigmoid(0)=0.5,对结果的预测不具有任何倾向性。</div></pre></td></tr></table></figure></p>
<p>2.对于测试数据中出现label标签缺失时，则丢弃该数据，因为很难替代该特征。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/04/01/python学习小结/" rel="next" title="python学习小结">
                <i class="fa fa-chevron-left"></i> python学习小结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/08/27/分类之支持向量机/" rel="prev" title="分类之支持向量机">
                分类之支持向量机 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="jimmydug" />
          <p class="site-author-name" itemprop="name">jimmydug</p>
           
              <p class="site-description motion-element" itemprop="description">Want Success Entremely!!!</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">Artikel</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性分类器（来自python机器学习及实践）"><span class="nav-number">1.</span> <span class="nav-text">线性分类器（来自python机器学习及实践）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度上升-来自机器学习实战第5章"><span class="nav-number">2.</span> <span class="nav-text">梯度上升(来自机器学习实战第5章)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#随机梯度上升-SGA"><span class="nav-number">3.</span> <span class="nav-text">随机梯度上升(SGA)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#用Logistic回归进行二分类预测（分类任务）"><span class="nav-number">4.</span> <span class="nav-text">用Logistic回归进行二分类预测（分类任务）</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jimmydug</span>
</div>


<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  





  



  
  

  

  

  

  


  

</body>
</html>
